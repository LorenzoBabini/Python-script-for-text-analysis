{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "450b0421",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://upload.wikimedia.org/wikipedia/commons/e/e1/CC_BY_icon.svg\"><br />\n",
    "\n",
    "Created by Lorenzo Babini and under [Creative Commons CC BY License](https://creativecommons.org/licenses/by/4.0/)<br />\n",
    "For questions/comments/improvements, email lorenzo.babini@unicatt.it.<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2be9a5",
   "metadata": {},
   "source": [
    "### Intro\n",
    "\n",
    "##### Opening and print a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c05994",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_name = \"/text.txt\" # insert the url of the text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb52dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(text_name, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "text = text.replace('\\n\\n', '\\n')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b03500d",
   "metadata": {},
   "source": [
    "# spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a0aa14",
   "metadata": {},
   "source": [
    "### Lemmatizer & POS Tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35814ce4",
   "metadata": {},
   "source": [
    "##### Importing and setting spaCy\n",
    "\n",
    "spaCy models (like \"it_core_news_sm\") have to be previously downloaded following this instructions: https://spacy.io/usage/models.\n",
    "\n",
    "You can find and download other models from Hugging Face. In this case you have to indicate the url path of the the donwloaded model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52187665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('it_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5810dbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0616da13",
   "metadata": {},
   "source": [
    "##### Printing token, lemma and POS tag in two different ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8904f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TOKEN\".ljust(16), \"LEMMA\", \"POS TAG\".rjust(15))\n",
    "for token in my_doc :\n",
    "    if str(token) != '\\n':\n",
    "        print(str(token).ljust(10), '|', str(token.lemma_).rjust(10), '|', str(token.pos_).rjust(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f862a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for token in my_doc :\n",
    "    if str(token) != '\\n':\n",
    "        print(f'word: {str(token).ljust(10)}\\tlemma: {str(token.lemma_.rjust(10))}\\tpos tag: {str(token.pos_)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c05edb",
   "metadata": {},
   "source": [
    "##### Creating and save a CSV with structured data (token, lemma, pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afec5088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "w = csv.writer(open((\"/spacy_data.csv\"), \"w\", newline=\"\")) #insert the url of the CSV file to save\n",
    "for token in my_doc:\n",
    "    if token.text.isalpha() == True :\n",
    "        w.writerow([token, token.lemma_, token.pos_])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bd4a7d",
   "metadata": {},
   "source": [
    "### NER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23341c0c",
   "metadata": {},
   "source": [
    "##### Importing and setting spaCy (see above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f126c38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using spacy.load().\n",
    "import spacy\n",
    "nlp_800 = spacy.load(\"\") ## insert model name or url path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db2a0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_other_doc = nlp_800(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e70b7a",
   "metadata": {},
   "source": [
    "##### Printing entitites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38939548",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in my_other_doc.ents :\n",
    "    print(ent.text, '|', ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585680fd",
   "metadata": {},
   "source": [
    "##### Creating and save a CSV with entities (entity, entity label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063fa0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "w = csv.writer(open((\"/spacy_data_ent.csv\"), \"w\", newline=\"\")) #insert the url of the CSV file to save\n",
    "for ent in my_other_doc.ents :\n",
    "    w.writerow([ent.text, ent.label_])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c302b733",
   "metadata": {},
   "source": [
    "# Stanza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5160566",
   "metadata": {},
   "source": [
    "For more details, see: https://stanfordnlp.github.io/stanza/usage.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892daef0",
   "metadata": {},
   "source": [
    "##### Import and setting Stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54bfb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a7f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_stanza = stanza.Pipeline(lang='it', processors='tokenize,mwt,pos,lemma,ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a2acb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_second_doc = nlp_stanza(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917c14e2",
   "metadata": {},
   "source": [
    "##### Printing token, lemma, POS tag and grammar features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccfde81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*[f'word: {word.text.ljust(10)}\\tlemma: {word.lemma.rjust(10)}\\tpos: {word.upos}\\tfeats: {word.feats if word.feats else \"_\"}' for sent in my_second_doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0863977e",
   "metadata": {},
   "source": [
    "##### Creating and save a CSV with structured data (token, lemma, POS, grammar features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63eb4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "w = csv.writer(open((\"/stanza_data.csv\"), \"w\", newline=\"\")) #insert the url of the CSV file to save\n",
    "for sent in my_second_doc.sentences:\n",
    "    for word in sent.words:\n",
    "        w.writerow([word.text, word.lemma, word.upos, word.feats if word.feats else \"_\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9067d9d8",
   "metadata": {},
   "source": [
    "##### Printing entities and type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed6e6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*[f'entity: {ent.text.ljust(9)}\\ttype: {ent.type}' for ent in my_second_doc.ents], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887594af",
   "metadata": {},
   "source": [
    "##### Creating and save a CSV with entities (entity, entity type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7a1ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "w = csv.writer(open((\"/stanza_data_ent.csv\"), \"w\", newline=\"\")) #insert the url of the CSV file to save\n",
    "for ent in my_second_doc.ents:\n",
    "    w.writerow([ent.text, ent.type])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
